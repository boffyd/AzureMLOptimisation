{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1616824648594
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-141428\n",
      "Azure region: southcentralus\n",
      "Subscription id: a0a76bad-11a1-4a2d-9887-97a29122c8ed\n",
      "Resource group: aml-quickstarts-141428\n"
     ]
    }
   ],
   "source": [
    "# Create a new workspace and define an experiment.\n",
    "\n",
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "#ws = Workspace.get(name=\"udacity-project\")\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "# Choose a name for the experiment\n",
    "experiment_name = 'udacity-project'\n",
    "exp = Experiment(workspace=ws, name= experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1616824675542
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Createa  compute cluster to provision VM Resources.\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Choose a name for the cluster\n",
    "cpu_cluster_name = 'cpu-cluster-01'\n",
    "\n",
    "#Verify that the culster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = ws, name = cpu_cluster_name)\n",
    "    print('Found existing cluster, use it')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_D2_V2', max_nodes = 4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Setup Hyperparameter Tuning with Hyperdrive.\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "import os\n",
    "\n",
    "#Define the parameter search space/method\n",
    "# Specify parameter sampler \n",
    "ps = RandomParameterSampling({\n",
    "    'learning_rate': uniform(0.05,0.1),\n",
    "    'batch_size': choice(16,32,64,128)})\n",
    "\n",
    "# Specify an early termination Policy\n",
    "# Other options are median policy\n",
    "# Bandit policy stops if its less than 10% of best model, starting and interval 5\n",
    "early_termination_policypolicy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = ### YOUR CODE HERE ###\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(run_config=script_run_config,\n",
    "     hyperparameter_sampling=param_sampling,\n",
    "     policy=early_termination_policy,\n",
    "     primary_metric_name=\"accuracy\",\n",
    "     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "     max_total_runs=100,\n",
    "     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "hyperdrive_run = experiment.submit(hd_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Aruguments']\n",
    "\n",
    "print('Best Run id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['accuracy'])\n",
    "print('\\n learning rate', parameter_values[3])\n",
    "print('\\n keep probability:', parametr_vlues[5])\n",
    "print('\\n batch size:', parameter_values[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1616826843997
    }
   },
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "import pandas as pd\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "#  path to URL from Chrome DevTools Console\n",
    "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "#  read remote URL data to DataFrame\n",
    "ds = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1616827024906
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
    "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    #x_df = data.to_pandas_dataframe().dropna(), not required from original code, data is already a dataframe.\n",
    "    x_df = data.dropna()\n",
    "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
    "    x_df.drop(\"job\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(jobs)\n",
    "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
    "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
    "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(contact)\n",
    "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
    "    x_df.drop(\"education\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(education)\n",
    "    x_df[\"month\"] = x_df.month.map(months)\n",
    "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
    "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
    "\n",
    "    y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    return x_df, y_df #two outputs, x_df and y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1616827026535
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "\n",
    "x, y = clean_data(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-725e6deadd7b>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-725e6deadd7b>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    primary_metric= 'AUC_weighted',\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task= 'classification'\n",
    "    primary_metric = 'AUC_weighted',\n",
    "    training_data= ds,\n",
    "    label_column_name = 'y',\n",
    "    n_cross_validations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws,\"automl_udacity_project\")\n",
    "run.experiment.submit(config = automml_config, show_output = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
