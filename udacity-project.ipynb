{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning Engineer\n",
    "### Project 1 - Optimising an ML Pipeline in Azure\n",
    "\n",
    "#### Step 1 Create a workspace\n",
    "In this step we are making an Azure Workspace and setting up an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1616824648594
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-141428\n",
      "Azure region: southcentralus\n",
      "Subscription id: a0a76bad-11a1-4a2d-9887-97a29122c8ed\n",
      "Resource group: aml-quickstarts-141428\n"
     ]
    }
   ],
   "source": [
    "# Create a new workspace and define an experiment.\n",
    "\n",
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "#ws = Workspace.get(name=\"udacity-project\")\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "# Choose a name for the experiment\n",
    "experiment_name = 'udacity-project'\n",
    "exp = Experiment(workspace=ws, name= experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Compute\n",
    "Create a new compute or use an existing one if its present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1616824675542
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create a compute cluster to provision VM Resources.\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Choose a name for the cluster\n",
    "cpu_cluster_name = 'cpu-cluster-01'\n",
    "\n",
    "#Verify that the culster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = ws, name = cpu_cluster_name)\n",
    "    print('Found existing cluster, use it')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_D2_V2', max_nodes = 4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-0aa263d9e401>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0aa263d9e401>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    compute_target = compute_target)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Setup Hyperparameter Tuning with Hyperdrive.\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform,choice\n",
    "import os\n",
    "\n",
    "#Define the parameter search space/method\n",
    "# Specify parameter sampler, in this case we are looking to get defined ranges and pass back to the SKILEARN\n",
    "# training model.\n",
    "\n",
    "ps = RandomParameterSampling({\n",
    "    '--C': choice(0.05,0.1),\n",
    "    '--max_iter': choice(16,32,64,128)})\n",
    "\n",
    "# Specify an early termination Policy\n",
    "# Other options are median policy, have stuck with bandit for simplification\n",
    "# Bandit policy stops if its less than 10% of best model, starting and interval 5\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "#creates a training director.\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py ### YOUR CODE HERE ###\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory='.',\n",
    "                      script='train.py',\n",
    "                      arguments = ['--C',0.05,'--max_iter',16],\n",
    "                      compute_target = compute_target)\n",
    "\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(run_config = est,\n",
    "                                     hyperparameter_sampling = ps,\n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name = 'accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs = 50,\n",
    "                                     max_concurrent_runs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "hyperdrive_run = experiment.submit(hyperdrive_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/ml-frameworks/scikit-learn/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])\n",
    "\n",
    "print(best_run.get_file_names())\n",
    "\n",
    "model = best_run.register_model(model_name='hyperdrive', model_path='outputs/model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compare against AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the experiment\n",
    "experiment_name = 'AutoML-udacity-project'\n",
    "exp = Experiment(workspace=ws, name= experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1616826843997
    }
   },
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "import pandas as pd\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "#  path to URL from Chrome DevTools Console\n",
    "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "#  read remote URL data to DataFrame\n",
    "#ds = TabularDatasetFactory.from_delimited_files(url,separator = ',')\n",
    "ds = TabularDatasetFactory.from_delimited_files(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1616827026535
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "\n",
    "#automl settings have the optios to assign the dataframe and identify a target variable within it.\n",
    "datafinal = pd.concat([x,y], axis = 1)\n",
    "\n",
    "x_train, x_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-725e6deadd7b>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-725e6deadd7b>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    primary_metric= 'AUC_weighted',\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "\n",
    "#define automl settings\n",
    "automl_settings {\n",
    "    'experiment_timeout_minutes' : 30,\n",
    "    'primary_metric' : 'Accuracy',\n",
    "    'n_cross_validations : 5\n",
    "    'enable_onnx_compatible_models' : True')\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             x = x_train,\n",
    "                             y = y_train,\n",
    "                             **automl_settings)\n",
    "    \n",
    "#automl_config = AutoMLConfig(task = 'classification',\n",
    "                             #training_data= ds,\n",
    "                             #label_column_name = 'y',\n",
    "                             #**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws,\"automl_udacity_project\")\n",
    "run.experiment.submit(config = automml_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "To ensure we don't continue to acrue cost for the resources, delete resources.\n",
    "\n",
    "#### Delete Compute Instance and Cluster\n",
    "1. In the Microsoft Azure Machine Learning Portal, select Compute on the far left.\n",
    "\n",
    "2. From the list, select the compute instances and or compute clsuters you created.\n",
    "\n",
    "3. Select Delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
